{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR\n",
    "\n",
    "\n",
    "| X1    | X2       | Out  |\n",
    "| :-----: |:--------:| :----:|\n",
    "|   0   |    0     |   0  |\n",
    "|   0   |    1     |   1  |\n",
    "|   1   |    0     |   1  |\n",
    "|   1   |    1     |   0  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "target_output = np.array([[0,1,1,0]])\n",
    "target_output = target_output.reshape(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0. Error 0.441245814351761\n",
      "epoch 1000. Error 0.012968341182077792\n",
      "epoch 2000. Error 0.0014554728665179817\n",
      "epoch 3000. Error 0.0008567365564094986\n",
      "epoch 4000. Error 0.0006128457699500767\n",
      "epoch 5000. Error 0.00044187489655800327\n",
      "epoch 6000. Error 0.00031877054481288525\n",
      "epoch 7000. Error 0.00022999445989568823\n",
      "epoch 8000. Error 0.00016595310319361678\n",
      "epoch 9000. Error 0.0001197483532638377\n",
      "epoch 10000. Error 8.640994101538624e-05\n",
      "epoch 11000. Error 6.235401942189522e-05\n",
      "epoch 12000. Error 4.4995566408134735e-05\n",
      "epoch 13000. Error 3.2469692264003314e-05\n",
      "epoch 14000. Error 2.34308954326079e-05\n",
      "epoch 15000. Error 1.690834970302646e-05\n",
      "epoch 16000. Error 1.2201542122503017e-05\n",
      "epoch 17000. Error 8.804994031219593e-06\n",
      "epoch 18000. Error 6.353953234783383e-06\n",
      "epoch 19000. Error 4.58521177743032e-06\n",
      "epoch 20000. Error 3.308834914172998e-06\n",
      "epoch 21000. Error 2.387761952049594e-06\n",
      "epoch 22000. Error 1.723086658134143e-06\n",
      "epoch 23000. Error 1.2434356946866565e-06\n",
      "epoch 24000. Error 8.973040465098947e-07\n",
      "epoch 25000. Error 6.475241702275092e-07\n",
      "epoch 26000. Error 4.672748278311545e-07\n",
      "epoch 27000. Error 3.37200974143137e-07\n",
      "epoch 28000. Error 2.43335391170163e-07\n",
      "epoch 29000. Error 1.7559888437768123e-07\n",
      "epoch 30000. Error 1.267179793873474e-07\n",
      "epoch 31000. Error 9.144389867543623e-08\n",
      "epoch 32000. Error 6.598895252452053e-08\n",
      "epoch 33000. Error 4.761981908796287e-08\n",
      "epoch 34000. Error 3.436404261147885e-08\n",
      "epoch 35000. Error 2.4798234465883695e-08\n",
      "epoch 36000. Error 1.78952296314705e-08\n",
      "epoch 37000. Error 1.2913792035718075e-08\n",
      "epoch 38000. Error 9.319021387899085e-09\n",
      "epoch 39000. Error 6.724915346811855e-09\n",
      "epoch 40000. Error 4.852922230735857e-09\n",
      "epoch 41000. Error 3.5020300548360694e-09\n",
      "epoch 42000. Error 2.5271811310290104e-09\n",
      "epoch 43000. Error 1.8236978593932918e-09\n",
      "epoch 44000. Error 1.3160410539114764e-09\n",
      "epoch 45000. Error 9.496987640744692e-10\n",
      "epoch 46000. Error 6.853342338075663e-10\n",
      "epoch 47000. Error 4.945598375272198e-10\n",
      "epoch 48000. Error 3.5689096122837327e-10\n",
      "epoch 49000. Error 2.575443192043281e-10\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([[0.1], [0.2]])\n",
    "bias = 0.3\n",
    "lr = 0.01\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):  # we need the derivative in GD\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "for epoch in range(50000):\n",
    "    \n",
    "    inputs = input_features                  \n",
    "    in_o = np.dot(inputs, weights) + bias    #feed-forward input\n",
    "    out_o = sigmoid(in_o)           # feed-forward output        \n",
    "    error = out_o - target_output   # back-propogation \n",
    "    \n",
    "    x = error.sum()\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'epoch {epoch}. Error {x}')\n",
    "\n",
    "    derr_dout = error                     # 1st deriv\n",
    "    dout_din = sigmoid_derivative(out_o)  # 2nd deriv\n",
    "\n",
    "    deriv = derr_dout * dout_din \n",
    "    \n",
    "    inputs = input_features.T           # 3rd deriv\n",
    "    \n",
    "    deriv_final = np.dot(inputs,deriv)  # that's the one we were looking for\n",
    "\n",
    "    weights -= lr * deriv_final    # update weights \n",
    "    for i in deriv:\n",
    "        bias -= lr * i             # update bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Error is decreasing.\n",
    "\n",
    "**Good??** Let's make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] --> [0.5]\n",
      "[0, 1] --> [0.5]\n",
      "[1, 0] --> [0.5]\n",
      "[1, 1] --> [0.5]\n"
     ]
    }
   ],
   "source": [
    "for pair in [[0,0], [0,1], [1,0], [1,1]]:\n",
    "    point = np.array([1,0])\n",
    "    res1 = np.dot(point, weights) + bias  # step1\n",
    "    res2 = sigmoid(res1)     # step2\n",
    "    print(pair, '-->', res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results are the same...\n",
    "\n",
    "**XOR is not linearly separable. Perceptron won't work.** \n",
    "\n",
    "## Why?\n",
    "\n",
    "If you look at the truth table of the operator you find the following situation:\n",
    "\n",
    "<img src=\"xor.png\" width=\"300\"/>\n",
    "\n",
    "There is no linear function that can correctly separate the two classes.\n",
    "\n",
    "**Solution**: add a hidden layer with 2 neurons. One for each \"line\" it would be nice to draw.\n",
    "\n",
    "<img src=\"xornn.png\" width=\"300\"/>\n",
    "\n",
    "That is:\n",
    "  * 2 neurons in the input layer\n",
    "  * 2 neurons in the hidden layer\n",
    "  * 1 neuron in the output layer\n",
    "  * 4 weights for the hidden layer\n",
    "  * 2 weights for the output layer\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add some neurons... by hand\n",
    "Refer to the perceptron notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [[0.01930689]\n",
      " [0.98336113]\n",
      " [0.98338449]\n",
      " [0.01721923]]\n",
      "Loss: [[-0.01930689]\n",
      " [ 0.01663887]\n",
      " [ 0.01661551]\n",
      " [-0.01721923]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "num_neurons_input_layer = 2 \n",
    "num_neurons_hidden_layer = 2 \n",
    "num_neurons_output_layer = 1\n",
    "\n",
    "# instead of trying some values, let's sample from a uniform distribution  \n",
    "hidden_weights = np.random.uniform(size=\n",
    "                                   (num_neurons_input_layer, \n",
    "                                    num_neurons_hidden_layer))   # 2x2\n",
    "hidden_bias = np.random.uniform(size=(1, \n",
    "                                      num_neurons_hidden_layer))                            # 1x2\n",
    "output_weights = np.random.uniform(size=(num_neurons_hidden_layer, \n",
    "                                         num_neurons_output_layer))  # 2x2\n",
    "output_bias = np.random.uniform(size=(1, \n",
    "                                      num_neurons_output_layer))                            # 1x2\n",
    "\n",
    "epochs = 50000\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "for _ in range(epochs):\n",
    "    # Feed forward: Input to Hidden\n",
    "    hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "    hidden_layer_activation += hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "    \n",
    "    # Feed forward: Hidden to output\n",
    "    output_layer_activation = np.dot(hidden_layer_output,\n",
    "                                     output_weights)\n",
    "    output_layer_activation += output_bias\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "    # back-propagation\n",
    "    error = expected_output - predicted_output\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    \n",
    "    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(\n",
    "        hidden_layer_output)\n",
    "\n",
    "    #updates\n",
    "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "    hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "    \n",
    "\n",
    "print(f\"Output: {predicted_output}\")\n",
    "print(f\"Loss: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good. `[0.01, 0.98, 0.97, 0.01]` instead of `[0, 1, 1, 0]`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
